{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NJpoAW2TDheL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6dd942a-852a-4931-b4c5-f4a4d4bba5a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q ultralytics kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  # type: ignore\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print(\"Google Drive mounted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgElZLo_3l_a",
        "outputId": "e638ca19-3254-439f-82d7-9a06eded0116"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_DATASETS_PATH'] = '/content/datasets'"
      ],
      "metadata": {
        "id": "zhPK3lv3D4yo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"calebstephen/food-images-and-labels-dataset-for-yolov5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_udUsVaTDqew",
        "outputId": "033c3a6a-e365-4504-d386-738488fa7a53"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/calebstephen/food-images-and-labels-dataset-for-yolov5?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39.5M/39.5M [00:03<00:00, 12.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "local_path = Path('/content/food-images-and-labels-dataset-for-yolov5')\n",
        "shutil.copytree(path, local_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K69g192dYsuZ",
        "outputId": "4bb8ab7a-7a51-401c-a0f4-2ea95014d791"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/food-images-and-labels-dataset-for-yolov5')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q ultralytics>=8.0.0 kagglehub>=0.3.0 pandas>=1.5.0 torch>=1.8.0 torchvision>=0.9.0 Pillow>=8.0.0 opencv-python>=4.6.0 matplotlib>=3.3.0 scikit-learn>=1.0.0"
      ],
      "metadata": {
        "id": "2keT-BoiEH5X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path; import shutil, os\n",
        "root = Path(local_path)  # Use local copy"
      ],
      "metadata": {
        "id": "OhvpBfZzHMPE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "import yaml\n",
        "\n",
        "GOOGLE_DRIVE_BASE_PATH = Path(\"/content/drive/MyDrive/FoodDetectCheckpoints\")\n",
        "PROJECT_NAME = \"food_detection_results\"\n",
        "RUN_NAME = \"yolo_detection_run_2\"\n",
        "\n",
        "DRIVE_PROJECT_PATH = GOOGLE_DRIVE_BASE_PATH / PROJECT_NAME\n",
        "FINAL_SAVE_PATH = DRIVE_PROJECT_PATH / RUN_NAME\n",
        "\n",
        "DATASET_DIR = Path(\"/content/food-images-and-labels-dataset-for-yolov5\")\n",
        "DATASET_YAML = DATASET_DIR / \"data.yaml\"\n",
        "\n",
        "#  check if the YOLO-formatted dataset exists and is valid\n",
        "def check_detection_dataset():\n",
        "    dataset_dir = DATASET_DIR\n",
        "    yaml_file = DATASET_YAML\n",
        "\n",
        "    if not dataset_dir.exists():\n",
        "        print(f\"Dataset directory '{dataset_dir}' not found.\")\n",
        "        return False\n",
        "\n",
        "    required_dirs = [\n",
        "        dataset_dir / \"train\" / \"images\",\n",
        "        dataset_dir / \"train\" / \"labels\",\n",
        "        dataset_dir / \"valid\" / \"images\",\n",
        "        dataset_dir / \"valid\" / \"labels\",\n",
        "    ]\n",
        "\n",
        "    for dir_path in required_dirs:\n",
        "        if not dir_path.exists():\n",
        "            print(f\"Missing directory: {dir_path}\")\n",
        "            return False\n",
        "\n",
        "    if not yaml_file.exists():\n",
        "        print(f\"Missing YAML config: {yaml_file}\")\n",
        "        return False\n",
        "\n",
        "    def count_files(path):\n",
        "        return len(list(path.glob(\"*\")))\n",
        "\n",
        "    train_images = count_files(dataset_dir / \"train\" / \"images\")\n",
        "    val_images = count_files(dataset_dir / \"valid\" / \"images\")\n",
        "    train_labels = count_files(dataset_dir / \"train\" / \"labels\")\n",
        "    val_labels = count_files(dataset_dir / \"valid\" / \"labels\")\n",
        "\n",
        "    if train_images == 0 or val_images == 0:\n",
        "        print(f\"No images found: train={train_images}, val={val_images}\")\n",
        "        return False\n",
        "\n",
        "    if train_labels == 0 or val_labels == 0:\n",
        "        print(f\"No labels found: train={train_labels}, val={val_labels}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"YOLO dataset found at: {dataset_dir}\")\n",
        "    print(f\"Training: {train_images} images, {train_labels} labels\")\n",
        "    print(f\"Validation: {val_images} images, {val_labels} labels\")\n",
        "\n",
        "    try:\n",
        "        with open(yaml_file, 'r') as f:\n",
        "            config = yaml.safe_load(f)\n",
        "\n",
        "        num_classes = config.get('nc', 0)\n",
        "        class_names = config.get('names', [])\n",
        "\n",
        "        print(f\"Categories: {num_classes} classes\")\n",
        "        print(f\"Classes: {class_names[:5]}{'...' if len(class_names) > 5 else ''}\")\n",
        "\n",
        "    except yaml.YAMLError as e:\n",
        "        print(f\"Error reading YAML config file: {e}\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# check for GPU availability\n",
        "def check_gpu():\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "        print(f\"GPU available: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"No GPU available, will use CPU\")\n",
        "        return False\n",
        "\n",
        "# save checkpoints in google drive\n",
        "def setup_google_drive_path():\n",
        "    print(f\"\\nSetting up Google Drive path\")\n",
        "    try:\n",
        "        os.makedirs(DRIVE_PROJECT_PATH, exist_ok=True)\n",
        "        print(f\"Checkpoint directory created/verified: {DRIVE_PROJECT_PATH}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to access or create Google Drive path: {DRIVE_PROJECT_PATH}\")\n",
        "        print(f\"Error: {e}\")\n",
        "        return False\n",
        "\n",
        "# train\n",
        "def train_detection_model():\n",
        "\n",
        "    print(\"Starting YOLO Food Detection Training\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if not check_detection_dataset():\n",
        "        return False\n",
        "\n",
        "    if not setup_google_drive_path():\n",
        "        return False\n",
        "\n",
        "    gpu_available = check_gpu()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\nLoading YOLOv8s detection model...\")\n",
        "    model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "    config = {\n",
        "        'data': str(DATASET_YAML.absolute()),\n",
        "        'imgsz': 640,\n",
        "        'epochs': 50,\n",
        "        'batch': 16 if gpu_available else 8,\n",
        "        'workers': min(os.cpu_count() // 2, 4) if os.cpu_count() else 2,\n",
        "        'device': 0 if gpu_available else 'cpu',\n",
        "\n",
        "        'project': str(DRIVE_PROJECT_PATH),\n",
        "        'name': RUN_NAME,\n",
        "\n",
        "        'save': True,\n",
        "        'save_period': 1,\n",
        "        'cache': True,\n",
        "        'verbose': True,\n",
        "        'plots': True,\n",
        "        'patience': 15,\n",
        "        'lr0': 0.01,\n",
        "        'lrf': 0.01,\n",
        "        'momentum': 0.937,\n",
        "        'weight_decay': 0.0005,\n",
        "        'warmup_epochs': 3,\n",
        "        'warmup_momentum': 0.8,\n",
        "        'warmup_bias_lr': 0.1,\n",
        "        'box': 7.5,\n",
        "        'cls': 0.5,\n",
        "        'dfl': 1.5,\n",
        "        'pose': 12.0,\n",
        "        'kobj': 1.0,\n",
        "        'label_smoothing': 0.0,\n",
        "        'nbs': 64,\n",
        "        'hsv_h': 0.015,\n",
        "        'hsv_s': 0.7,\n",
        "        'hsv_v': 0.4,\n",
        "        'degrees': 0.0,\n",
        "        'translate': 0.1,\n",
        "        'scale': 0.5,\n",
        "        'shear': 0.0,\n",
        "        'perspective': 0.0,\n",
        "        'flipud': 0.0,\n",
        "        'fliplr': 0.5,\n",
        "        'mosaic': 1.0,\n",
        "        'mixup': 0.0,\n",
        "        'copy_paste': 0.0,\n",
        "        'auto_augment': 'randaugment',\n",
        "        'erasing': 0.4,\n",
        "        'crop_fraction': 1.0,\n",
        "    }\n",
        "\n",
        "    print(f\"\\nTraining Configuration:\")\n",
        "    print(f\"Model: YOLOv8s Detection\")\n",
        "    print(f\"Dataset: {config['data']}\")\n",
        "    print(f\"Epochs: {config['epochs']}\")\n",
        "    print(f\"Batch size: {config['batch']}\")\n",
        "    print(f\"Device: {config['device']}\")\n",
        "    print(f\"Checkpoints saving to: {FINAL_SAVE_PATH}\")\n",
        "\n",
        "    print(f\"\\nStarting detection training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        results = model.train(**config)\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        print(f\"\\nTraining completed in {training_time/60:.1f} minutes\")\n",
        "\n",
        "        print(f\"\\nRunning final validation...\")\n",
        "        val_results = model.val(data=str(DATASET_YAML.absolute()),\n",
        "                                 imgsz=640,\n",
        "                                 batch=config['batch'])\n",
        "\n",
        "        print(f\"\\nTraining Results:\")\n",
        "        print(f\"Best model saved to: {FINAL_SAVE_PATH / 'weights' / 'best.pt'}\")\n",
        "        print(f\"Last model saved to: {FINAL_SAVE_PATH / 'weights' / 'last.pt'}\")\n",
        "        print(f\"Results plots saved to: {FINAL_SAVE_PATH}/\")\n",
        "\n",
        "        # Show some key metrics\n",
        "        if hasattr(val_results, 'box'):\n",
        "            print(f\"\\nDetection Metrics:\")\n",
        "            print(f\"mAP50: {val_results.box.map50:.3f}\")\n",
        "            print(f\"mAP50-95: {val_results.box.map:.3f}\")\n",
        "            print(f\"Precision: {val_results.box.mp:.3f}\")\n",
        "            print(f\"Recall: {val_results.box.mr:.3f}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nTraining failed with error: {e}\")\n",
        "        return False\n",
        "\n",
        "    finally:\n",
        "        # Cleanup\n",
        "        del model\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        success = train_detection_model()\n",
        "        if success:\n",
        "            print(f\"\\nDetection training completed successfully\")\n",
        "            print(f\"Check '{FINAL_SAVE_PATH}' on Google Drive for results\")\n",
        "            return 0\n",
        "        else:\n",
        "            print(f\"\\nTraining failed\")\n",
        "            return 1\n",
        "    except KeyboardInterrupt:\n",
        "        print(f\"\\nTraining interrupted by user\")\n",
        "        return 1\n",
        "    except Exception as e:\n",
        "        print(f\"\\nUnexpected error: {e}\")\n",
        "        return 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sys.exit(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cy25DHItPGT_",
        "outputId": "a9d234df-f2cf-4d1c-dbbc-9741eb0235a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Starting YOLO Food Detection Training\n",
            "==================================================\n",
            "YOLO dataset found at: /content/food-images-and-labels-dataset-for-yolov5\n",
            "Training: 704 images, 704 labels\n",
            "Validation: 65 images, 65 labels\n",
            "Categories: 12 classes\n",
            "Classes: ['Apple', 'Chapathi', 'Chicken Gravy', 'Fries', 'Idli']...\n",
            "\n",
            "Setting up Google Drive path\n",
            "Checkpoint directory created/verified: /content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results\n",
            "GPU available: NVIDIA A100-SXM4-80GB (79.3 GB)\n",
            "\n",
            "Loading YOLOv8s detection model...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 21.5MB 477.3MB/s 0.0s\n",
            "\n",
            "Training Configuration:\n",
            "Model: YOLOv8s Detection\n",
            "Dataset: /content/food-images-and-labels-dataset-for-yolov5/data.yaml\n",
            "Epochs: 50\n",
            "Batch size: 16\n",
            "Device: 0\n",
            "Checkpoints saving to: /content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2\n",
            "\n",
            "Starting detection training...\n",
            "WARNING âš ï¸ 'crop_fraction' is deprecated and will be removed in the future.\n",
            "WARNING âš ï¸ 'label_smoothing' is deprecated and will be removed in the future.\n",
            "Ultralytics 8.3.223 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/food-images-and-labels-dataset-for-yolov5/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_detection_run_2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 83.4MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2120692  ultralytics.nn.modules.head.Detect           [12, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,140,244 parameters, 11,140,228 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 303.8MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1209.9Â±469.6 MB/s, size: 49.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/food-images-and-labels-dataset-for-yolov5/train/labels... 704 images, 3 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 704/704 1.3Kit/s 0.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/food-images-and-labels-dataset-for-yolov5/train/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 949, len(boxes) = 1028. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 704/704 2.3Kit/s 0.3s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 454.3Â±330.5 MB/s, size: 57.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/food-images-and-labels-dataset-for-yolov5/valid/labels... 65 images, 1 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 65/65 1.1Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/food-images-and-labels-dataset-for-yolov5/valid/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 105, len(boxes) = 114. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 65/65 1.4Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 4 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50       3.5G     0.8909      3.534      1.445         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 7.5it/s 5.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.9it/s 1.6s\n",
            "                   all         65        114      0.513      0.479      0.531      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      4.29G     0.7433      1.623      1.303         55        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 10.6it/s 4.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.7it/s 0.3s\n",
            "                   all         65        114      0.662       0.57      0.682      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      4.33G      0.787      1.377      1.318         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.5it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.7it/s 0.3s\n",
            "                   all         65        114      0.765      0.454      0.593      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      4.37G      0.783      1.217      1.324         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 10.7it/s 4.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.5it/s 0.3s\n",
            "                   all         65        114      0.633      0.595      0.613      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50       4.4G     0.7975      1.188       1.33         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.2it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.9it/s 0.3s\n",
            "                   all         65        114      0.561      0.624      0.623      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      4.44G      0.779      1.139      1.296         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.3it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         65        114      0.683      0.614      0.681      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      4.47G       0.73      1.002      1.277         55        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.4it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.5it/s 0.3s\n",
            "                   all         65        114      0.581      0.606      0.599      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      4.51G     0.7375      1.004       1.28         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.0it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         65        114      0.671      0.673      0.707      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      4.55G     0.7212     0.9055      1.266         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.4it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.1it/s 0.3s\n",
            "                   all         65        114      0.721      0.662      0.734       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      4.58G     0.7053     0.8954      1.243         67        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.2it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.2it/s 0.3s\n",
            "                   all         65        114      0.796      0.651      0.727       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      4.62G     0.6724     0.8462      1.232         53        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.4it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.1it/s 0.3s\n",
            "                   all         65        114      0.724      0.701      0.784      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      4.66G     0.6864     0.8647      1.238         51        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.1it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         65        114       0.72      0.707      0.791      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      4.69G     0.6838      0.835      1.237         63        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.2it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         65        114      0.739      0.805      0.751      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      4.73G     0.6462     0.7429       1.21         66        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.6it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.9it/s 0.3s\n",
            "                   all         65        114       0.71      0.769      0.809      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      4.77G       0.63     0.7429      1.187         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.1it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         65        114      0.687      0.701      0.758      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50       4.8G      0.593     0.7263      1.173         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.5it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.0it/s 0.3s\n",
            "                   all         65        114      0.807      0.726      0.785      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      4.84G     0.5929     0.7071      1.173         53        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.1it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s\n",
            "                   all         65        114      0.734      0.833      0.859      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      4.87G     0.5944     0.6678       1.17         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.1it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         65        114       0.83      0.789      0.843      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      4.91G     0.5817       0.65      1.168         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.2it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         65        114      0.753      0.749       0.82      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      4.95G     0.5837     0.6763      1.165         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.2it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         65        114      0.747      0.831      0.848      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      4.98G     0.5515     0.6072      1.131         56        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.6it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.1it/s 0.3s\n",
            "                   all         65        114      0.789      0.793      0.879      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      5.02G     0.5679     0.5924       1.15         59        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.0it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.0it/s 0.3s\n",
            "                   all         65        114      0.776      0.745      0.801      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      5.05G     0.5272     0.5579      1.123         55        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.2it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         65        114      0.791      0.748      0.758      0.551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      5.09G     0.5245     0.5435      1.114         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.4it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         65        114      0.834      0.734      0.825      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      5.13G     0.5251      0.549      1.118         48        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 10.9it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s\n",
            "                   all         65        114      0.701      0.833       0.76      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      5.16G     0.5068     0.5117      1.108         62        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.3it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         65        114      0.764       0.74      0.773      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50       5.2G     0.4926      0.493      1.098         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.1it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.9it/s 0.3s\n",
            "                   all         65        114      0.733      0.799      0.821      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      5.24G     0.4896     0.5034      1.101         51        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.1it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.7it/s 0.3s\n",
            "                   all         65        114      0.748      0.823      0.778      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      5.27G      0.495     0.5078      1.101         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.7it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.7it/s 0.3s\n",
            "                   all         65        114      0.828      0.755      0.861      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      5.31G     0.4823     0.4924      1.081         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.2it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.1it/s 0.3s\n",
            "                   all         65        114      0.827      0.796      0.832      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      5.34G     0.4867     0.4891        1.1         62        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.7it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         65        114      0.756      0.749      0.799      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      5.38G     0.4717     0.4849      1.078         50        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.5it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.2it/s 0.3s\n",
            "                   all         65        114      0.719      0.832      0.782        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      5.45G     0.4584     0.4613      1.077         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 10.9it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         65        114      0.868      0.807      0.863      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      5.49G     0.4584     0.4383      1.069         53        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.2it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.1it/s 0.3s\n",
            "                   all         65        114      0.794      0.821      0.788      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      5.55G      0.445     0.4256      1.066         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.3it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         65        114      0.818      0.796      0.818       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      5.62G     0.4324     0.4146      1.055         64        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.3it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.0it/s 0.3s\n",
            "                   all         65        114       0.78      0.776      0.797      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      5.69G     0.4439     0.4196      1.067         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.3it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         65        114      0.813      0.807      0.848      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      5.73G     0.4448     0.4206      1.058         62        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.0it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.7it/s 0.3s\n",
            "                   all         65        114      0.867      0.743      0.839      0.659\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50       5.8G     0.4237     0.4019      1.047         48        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.1it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.2it/s 0.3s\n",
            "                   all         65        114      0.861      0.772      0.859       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      5.87G     0.4244     0.4037      1.058         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.3it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s\n",
            "                   all         65        114      0.901      0.775      0.875      0.718\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      6.02G     0.3463     0.3773      1.012         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 9.9it/s 4.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.1it/s 0.3s\n",
            "                   all         65        114      0.775      0.808      0.841      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      6.05G     0.3211      0.321     0.9878         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.5it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.4it/s 0.3s\n",
            "                   all         65        114      0.821      0.842      0.873      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      6.09G     0.3048     0.2965     0.9693         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.3it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.7it/s 0.3s\n",
            "                   all         65        114      0.857      0.824      0.893      0.689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      6.13G     0.2974     0.2895     0.9802         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.2it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.2it/s 0.3s\n",
            "                   all         65        114      0.846      0.813      0.883       0.74\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50       6.2G     0.2817     0.2702     0.9728         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.5it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.9it/s 0.3s\n",
            "                   all         65        114      0.862      0.847      0.878      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      6.27G      0.275     0.2615     0.9447         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.1it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.6it/s 0.3s\n",
            "                   all         65        114       0.91      0.798      0.878      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      6.34G     0.2514     0.2307     0.9472         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.5it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.9it/s 0.3s\n",
            "                   all         65        114      0.853      0.804      0.879      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      6.41G     0.2555      0.239     0.9382         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.4it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.7it/s 0.3s\n",
            "                   all         65        114       0.88      0.819      0.837      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      6.47G     0.2464     0.2404     0.9318         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.6it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 10.8it/s 0.3s\n",
            "                   all         65        114      0.858      0.818      0.833      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      6.51G     0.2515     0.2264     0.9331         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 44/44 11.4it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s\n",
            "                   all         65        114      0.838       0.82      0.873      0.702\n",
            "\n",
            "50 epochs completed in 0.068 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2/weights/best.pt...\n",
            "Ultralytics 8.3.223 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "Model summary (fused): 72 layers, 11,130,228 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 9.2it/s 0.3s\n",
            "                   all         65        114      0.845      0.813      0.883      0.741\n",
            "                 Apple          6         15      0.864        0.8      0.895       0.76\n",
            "              Chapathi          7          7      0.978          1      0.995      0.839\n",
            "         Chicken Gravy          6          6      0.959          1      0.995      0.723\n",
            "                 Fries          6          6      0.796      0.667        0.7      0.536\n",
            "                  Idli          6         14      0.961      0.714      0.891      0.694\n",
            "                 Pizza          6          6      0.833          1      0.995      0.843\n",
            "                  Rice          7          7      0.948      0.857      0.876      0.752\n",
            "                  Soda          6          7      0.969      0.714      0.846      0.803\n",
            "                  Vada          6         36      0.692      0.188      0.533      0.416\n",
            "                banana          1          1      0.297          1      0.995      0.995\n",
            "                burger          9          9      0.997          1      0.995      0.793\n",
            "Speed: 0.1ms preprocess, 1.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2\u001b[0m\n",
            "\n",
            "Training completed in 4.5 minutes\n",
            "\n",
            "Running final validation...\n",
            "Ultralytics 8.3.223 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "Model summary (fused): 72 layers, 11,130,228 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1262.8Â±166.6 MB/s, size: 49.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/food-images-and-labels-dataset-for-yolov5/valid/labels.cache... 65 images, 1 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 65/65 137.2Kit/s 0.0s\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 105, len(boxes) = 114. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.3it/s 1.5s\n",
            "                   all         65        114      0.846      0.813      0.883      0.741\n",
            "                 Apple          6         15      0.865        0.8      0.895       0.76\n",
            "              Chapathi          7          7      0.978          1      0.995      0.828\n",
            "         Chicken Gravy          6          6      0.959          1      0.995      0.723\n",
            "                 Fries          6          6      0.797      0.667        0.7      0.536\n",
            "                  Idli          6         14      0.965      0.714      0.892      0.692\n",
            "                 Pizza          6          6      0.834          1      0.995      0.843\n",
            "                  Rice          7          7      0.948      0.857      0.876      0.752\n",
            "                  Soda          6          7      0.968      0.714      0.846      0.816\n",
            "                  Vada          6         36      0.692      0.187      0.528      0.411\n",
            "                banana          1          1      0.298          1      0.995      0.995\n",
            "                burger          9          9      0.997          1      0.995      0.799\n",
            "Speed: 3.7ms preprocess, 3.9ms inference, 0.0ms loss, 6.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "\n",
            "Training Results:\n",
            "Best model saved to: /content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2/weights/best.pt\n",
            "Last model saved to: /content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2/weights/last.pt\n",
            "Results plots saved to: /content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2/\n",
            "\n",
            "Detection Metrics:\n",
            "mAP50: 0.883\n",
            "mAP50-95: 0.741\n",
            "Precision: 0.846\n",
            "Recall: 0.813\n",
            "\n",
            "Detection training completed successfully\n",
            "Check '/content/drive/MyDrive/FoodDetectCheckpoints/food_detection_results/yolo_detection_run_2' on Google Drive for results\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "0",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}